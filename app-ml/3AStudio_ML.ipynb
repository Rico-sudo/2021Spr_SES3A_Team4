{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3AStudio_ML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOnC4lEW3O79"
      },
      "source": [
        "import json  #create the json\n",
        "import shutil #copy images to train, test and valid dirs\n",
        "import os #files and dirs manipulation\n",
        "import math #split calculate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSEKp5R23b0b",
        "outputId": "c9ec8eed-22b6-4dd9-c04a-1c45664da2f7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIhQVrC13fqR"
      },
      "source": [
        "parent_dir = '/content/gdrive/MyDrive/Studio 3A/SnakeDataset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYMpQBOM3paj",
        "outputId": "8cfb145c-4ae4-4a13-e993-b25528c8cd87"
      },
      "source": [
        "database_dir = '/content/gdrive/MyDrive/Studio 3A/SnakeDataset/dataset'\n",
        "#show category folder list\n",
        "os.chdir(database_dir)\n",
        "category_list = list(filter(lambda x: os.path.isdir(x),os.listdir()))\n",
        "for category in category_list:\n",
        "  print(category)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "storeria-dekayi\n",
            "rhinocheilus-lecontei\n",
            "thamnophis-proximus\n",
            "thamnophis-elegans\n",
            "thamnophis-marcianus\n",
            "pituophis-catenifer\n",
            "thamnophis-radix\n",
            "pantherophis-vulpinus\n",
            "storeria-occipitomaculata\n",
            "thamnophis-sirtalis\n",
            "nerodia-erythrogaster\n",
            "pantherophis-spiloides\n",
            "pantherophis-obsoletus\n",
            "opheodrys-aestivus\n",
            "pantherophis-guttatus\n",
            "nerodia-sipedon\n",
            "pantherophis-alleghaniensis\n",
            "nerodia-rhombifer\n",
            "pantherophis-emoryi\n",
            "nerodia-fasciata\n",
            "heterodon-platirhinos\n",
            "lampropeltis-triangulum\n",
            "crotalus-ruber\n",
            "haldea-striatula\n",
            "crotalus-scutulatus\n",
            "crotalus-viridis\n",
            "lampropeltis-californiae\n",
            "diadophis-punctatus\n",
            "natrix-natrix\n",
            "masticophis-flagellum\n",
            "agkistrodon-contortrix\n",
            "crotalus-horridus\n",
            "crotalus-atrox\n",
            "agkistrodon-piscivorus\n",
            "coluber-constrictor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "-swjLJ8w3tFP",
        "outputId": "bbfd19c7-a146-45ef-e98d-6160488701a6"
      },
      "source": [
        "#creating training,validation, test\n",
        "data_set_dirs = ['train','valid','test']\n",
        "for dsdirs in data_set_dirs:\n",
        "  path = parent_dir + '/'+dsdirs\n",
        "  os.mkdir(path, 755)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-a6aa01fa0e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdsdirs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_set_dirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdsdirs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m755\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/gdrive/MyDrive/Studio 3A/SnakeDataset/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SZox4U_33o5"
      },
      "source": [
        "**Set split ratio, start splitting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQnlqoY53xlV"
      },
      "source": [
        "#define proportion of data\n",
        "train_prop = 0.6\n",
        "valid_prop = test_prop = (1-train_prop)/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoDyp11T38G3"
      },
      "source": [
        "#function to split data of each category into trainning, validation and testing set\n",
        "\n",
        "def create_dataset():\n",
        "  for ii,snake in enumerate(category_list):    \n",
        "    src_path = database_dir + '/' + snake\n",
        "    dest_dir1 = parent_dir+'/train/'+str(ii)\n",
        "    dest_dir2 = parent_dir+'/valid/'+str(ii)\n",
        "    dest_dir3 = parent_dir+'/test/'+str(ii)\n",
        "    \n",
        "    dest_dirs_list = [dest_dir1,dest_dir2,dest_dir3]\n",
        "    for dirs in dest_dirs_list:\n",
        "      os.mkdir(dirs,755 )\n",
        "    \n",
        "    #get files' names list from respective directories\n",
        "    os.chdir(src_path)\n",
        "    files = [f for f in os.listdir() if os.path.isfile(f)]\n",
        "    \n",
        "    #get training, testing and validation files count\n",
        "    train_count = math.ceil(train_prop*len(files))\n",
        "    valid_count = int((len(files)-train_count)/2)\n",
        "    test_count = valid_count\n",
        "    \n",
        "    #get files to segragate for train,test and validation data set\n",
        "    train_data_list = files[0: train_count]\n",
        "    valid_data_list = files[train_count+1:train_count+1+valid_count]  \n",
        "    test_data_list =  files[train_count+valid_count:]\n",
        "       \n",
        "  \n",
        "    for train_data in train_data_list:\n",
        "      train_path = src_path + '/' + train_data\n",
        "      shutil.copy(train_path,dest_dir1)\n",
        "    \n",
        "    for valid_data in valid_data_list:\n",
        "      valid_path = src_path + '/' + valid_data\n",
        "      shutil.copy(valid_path,dest_dir2)\n",
        "    \n",
        "    for test_data in test_data_list:\n",
        "      test_path = src_path + '/' + test_data\n",
        "      shutil.copy(test_path,dest_dir3)    \n",
        "    \n",
        "create_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-P5flDR09W4"
      },
      "source": [
        "Dataset https://drive.google.com/drive/folders/15FD7nbI0pSmOEqIiPYgQCkG_Z5xsCv_h?usp=sharing"
      ]
    }
  ]
}